{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import youtube comment scraper\n",
    "from comment_scraper import comment_scraper\n",
    "\n",
    "# Preprocess Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "nltk.download(\"vader_lexicon\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer\n",
    "# Build Model for sentiment analysis\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, HalvingGridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate Class and place Video that I want to scrape comments from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_scraper = comment_scraper(videoId = \"jb_lnAvZSa4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"youtube_comments_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>text</th>\n",
       "      <th>public</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@joeconley2023</td>\n",
       "      <td>2024-02-04T07:41:58Z</td>\n",
       "      <td>0</td>\n",
       "      <td>This game was just a pure failure by the raven...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@JustinUrgo</td>\n",
       "      <td>2024-02-04T07:35:41Z</td>\n",
       "      <td>0</td>\n",
       "      <td>How many times mahomes gotta get tackled for t...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Jaem-ml4lx</td>\n",
       "      <td>2024-02-04T05:11:10Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Taunting after somebody tackles you</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@faafouinatsai8826</td>\n",
       "      <td>2024-02-04T03:45:46Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Titan fan ðŸ˜‚</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Prettyfresh20</td>\n",
       "      <td>2024-02-04T02:37:24Z</td>\n",
       "      <td>0</td>\n",
       "      <td>After watching this game, I will say a few thi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author            updated_at  like_count  \\\n",
       "0      @joeconley2023  2024-02-04T07:41:58Z           0   \n",
       "1         @JustinUrgo  2024-02-04T07:35:41Z           0   \n",
       "2         @Jaem-ml4lx  2024-02-04T05:11:10Z           0   \n",
       "3  @faafouinatsai8826  2024-02-04T03:45:46Z           0   \n",
       "4      @Prettyfresh20  2024-02-04T02:37:24Z           0   \n",
       "\n",
       "                                                text  public  \n",
       "0  This game was just a pure failure by the raven...    True  \n",
       "1  How many times mahomes gotta get tackled for t...    True  \n",
       "2                Taunting after somebody tackles you    True  \n",
       "3                                        Titan fan ðŸ˜‚    True  \n",
       "4  After watching this game, I will say a few thi...    True  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This game was just a pure failure by the raven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many times mahomes gotta get tackled for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taunting after somebody tackles you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Titan fan ðŸ˜‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After watching this game, I will say a few thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  This game was just a pure failure by the raven...\n",
       "1  How many times mahomes gotta get tackled for t...\n",
       "2                Taunting after somebody tackles you\n",
       "3                                        Titan fan ðŸ˜‚\n",
       "4  After watching this game, I will say a few thi..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns = [\"author\", \"updated_at\", \"like_count\", \"public\"], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuations and special characters\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize, stem, lemmatize text and remove stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def remove_stopwords(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    stemmed_text = [stemmer.stem(token) for token in tokens]\n",
    "    lemmatized_text = [stemmer.stem(token) for token in stemmed_text]\n",
    "    return lemmatized_text\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelling the data using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SIA()\n",
    "def get_sentiment(tokens):\n",
    "    text = \" \".join(tokens)\n",
    "    scores = sia.polarity_scores(text)\n",
    "    if scores[\"compound\"] >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif scores[\"compound\"] <= 0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment\"] = df[\"text\"].apply(lambda x: get_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negative    2575\n",
       "Positive    2135\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23788\\2112936396.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"sentiment\"] = df[\"sentiment\"].replace(sentiment_replace_map)\n"
     ]
    }
   ],
   "source": [
    "sentiment_replace_map = {\"Negative\": 0, \"Positive\": 1}\n",
    "df[\"sentiment\"] = df[\"sentiment\"].replace(sentiment_replace_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>game pure failur raven defen play good play ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mani time mahom gotta get tackl ref blow whistl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>taunt somebodi tackl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>titan fan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch game say thing biggest thing mahom posse...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  game pure failur raven defen play good play ma...          1\n",
       "1    mani time mahom gotta get tackl ref blow whistl          0\n",
       "2                               taunt somebodi tackl          0\n",
       "3                                          titan fan          1\n",
       "4  watch game say thing biggest thing mahom posse...          1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"text\"]\n",
    "y = df[\"sentiment\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2651                                         ref get paid\n",
       "4397    lamar nutrid trash josh allen better energi bo...\n",
       "910                                    tf even swift girl\n",
       "124        christ sport beyond bore stop start stop start\n",
       "2955      surpri raven alway lose typic raven fashion sad\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Text To Numbers using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80       760\n",
      "           1       0.76      0.80      0.78       653\n",
      "\n",
      "    accuracy                           0.79      1413\n",
      "   macro avg       0.79      0.79      0.79      1413\n",
      "weighted avg       0.79      0.79      0.79      1413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multinomial_nb = MultinomialNB()\n",
    "multinomial_nb.fit(X_train, y_train)\n",
    "y_pred = multinomial_nb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       760\n",
      "           1       0.87      0.77      0.82       653\n",
      "\n",
      "    accuracy                           0.84      1413\n",
      "   macro avg       0.85      0.84      0.84      1413\n",
      "weighted avg       0.84      0.84      0.84      1413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Base LogReg Model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# Tuned LogReg Model\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "grid_search = GridSearchCV(estimator=logreg, param_grid=grid, n_jobs=-1, cv=5, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       760\n",
      "           1       0.87      0.86      0.87       653\n",
      "\n",
      "    accuracy                           0.88      1413\n",
      "   macro avg       0.88      0.88      0.88      1413\n",
      "weighted avg       0.88      0.88      0.88      1413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C = 10, penalty = \"l2\", solver = \"lbfgs\")\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86       760\n",
      "           1       0.82      0.86      0.84       653\n",
      "\n",
      "    accuracy                           0.85      1413\n",
      "   macro avg       0.85      0.85      0.85      1413\n",
      "weighted avg       0.85      0.85      0.85      1413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Base Dtree Model\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)\n",
    "y_pred = dtree.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 19, 'max_leaf_nodes': 23, 'min_samples_split': 6}\n"
     ]
    }
   ],
   "source": [
    "# Tuned DTree Model\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "max_depth = np.arange(1, 21).tolist()[0::2]\n",
    "min_samples_split = np.arange(2, 11).tolist()[0::2]\n",
    "max_leaf_nodes = np.arange(3, 26).tolist()[0::2]\n",
    "grid = dict(criterion = criterion, max_depth = max_depth, min_samples_split = min_samples_split, max_leaf_nodes = max_leaf_nodes)\n",
    "grid_search = HalvingGridSearchCV(dtree, param_grid= grid, n_jobs = -1, cv = 5, scoring = \"accuracy\", error_score=0)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86       760\n",
      "           1       0.83      0.84      0.84       653\n",
      "\n",
      "    accuracy                           0.85      1413\n",
      "   macro avg       0.85      0.85      0.85      1413\n",
      "weighted avg       0.85      0.85      0.85      1413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtree_tuned = DecisionTreeClassifier(criterion = \"gini\", max_depth = 19, max_leaf_nodes = 23, min_samples_split = 6)\n",
    "dtree_tuned.fit(X_train, y_train)\n",
    "y_pred = dtree_tuned.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87       760\n",
      "           1       0.83      0.88      0.85       653\n",
      "\n",
      "    accuracy                           0.86      1413\n",
      "   macro avg       0.86      0.86      0.86      1413\n",
      "weighted avg       0.86      0.86      0.86      1413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Base Random Forest Classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 25, 'max_leaf_nodes': 9, 'max_features': None, 'max_depth': 9}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [25, 50, 100, 150]\n",
    "max_features = [\"sqrt\", \"log2\", None]\n",
    "max_depth = [3, 6, 9]\n",
    "max_leaf_nodes = [3, 6, 9]\n",
    "grid = dict(n_estimators=n_estimators,max_features=max_features, max_depth = max_depth, max_leaf_nodes = max_leaf_nodes)\n",
    "grid_search = RandomizedSearchCV(estimator=rf, param_distributions=grid, n_iter = 20, n_jobs=-1, cv=5, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.90      0.79       760\n",
      "           1       0.83      0.55      0.66       653\n",
      "\n",
      "    accuracy                           0.74      1413\n",
      "   macro avg       0.77      0.73      0.73      1413\n",
      "weighted avg       0.76      0.74      0.73      1413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tuned Random Forest Classifier\n",
    "rf_tuned = RandomForestClassifier(n_estimators = 25, max_leaf_nodes = 6, max_features = None, max_depth = 6)\n",
    "rf_tuned.fit(X_train, y_train)\n",
    "y_pred = rf_tuned.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       760\n",
      "           1       0.85      0.85      0.85       653\n",
      "\n",
      "    accuracy                           0.86      1413\n",
      "   macro avg       0.86      0.86      0.86      1413\n",
      "weighted avg       0.86      0.86      0.86      1413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Base XGB Classifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6, 'gamma': 1.5, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "min_child_weight = [1, 5, 10, 20]\n",
    "gamma = [0.5, 1, 1.5]\n",
    "subsample = [0.6, 0.8, 1.0]\n",
    "colsample_bytree = [0.6, 0.8, 1.0]\n",
    "max_depth = [3, 4, 5]\n",
    "n_estimators = [50, 100, 200]\n",
    "learning_rate = [0.01, 0.05, 0.1]\n",
    "grid = dict(min_child_weight = min_child_weight, gamma = gamma, subsample = subsample, colsample_bytree = colsample_bytree, max_depth = max_depth, learning_rate = learning_rate, n_estimators= n_estimators)\n",
    "grid_search = HalvingGridSearchCV(estimator=xgb, param_grid=grid, n_jobs=-1, cv=5, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       760\n",
      "           1       0.86      0.85      0.86       653\n",
      "\n",
      "    accuracy                           0.87      1413\n",
      "   macro avg       0.87      0.87      0.87      1413\n",
      "weighted avg       0.87      0.87      0.87      1413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tuned XGBoost Classifier\n",
    "xgb_tuned = XGBClassifier(colsample_bytree = 0.6, gamma = 1.5, learning_rate = 0.1, max_depth = 5, min_child_weight = 1, n_estimators = 300, subsample = 1.0)\n",
    "xgb_tuned.fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       760\n",
      "           1       0.86      0.79      0.82       653\n",
      "\n",
      "    accuracy                           0.84      1413\n",
      "   macro avg       0.85      0.84      0.84      1413\n",
      "weighted avg       0.85      0.84      0.84      1413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Base Support Vector Machine\n",
    "svc= SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "C = [0.1, 1, 10, 100, 1000]\n",
    "gamma = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "kernel = [\"rbf\", \"linear\"]\n",
    "grid = dict(C = C, gamma = gamma, kernel = kernel)\n",
    "grid_search = HalvingGridSearchCV(estimator=svc, param_grid=grid, n_jobs=-1, cv=5, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       760\n",
      "           1       0.84      0.86      0.85       653\n",
      "\n",
      "    accuracy                           0.86      1413\n",
      "   macro avg       0.86      0.86      0.86      1413\n",
      "weighted avg       0.86      0.86      0.86      1413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tuned Support Vector Machine\n",
    "tuned_svc= SVC(C = 100, gamma = 0.1, kernel = \"rbf\")\n",
    "tuned_svc.fit(X_train, y_train)\n",
    "y_pred = tuned_svc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(df[\"text\"])\n",
    "y = list(df[\"sentiment\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "X_train_tokenized = tokenizer(X_train, padding = True, truncation = True, max_length = 512)\n",
    "X_test_tokenized = tokenizer(X_test, padding = True, truncation = True, max_length = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels = None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "test_dataset = Dataset(X_test_tokenized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    print(type(p))\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis = 1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true = labels, y_pred = pred)\n",
    "    recall = recall_score(y_true = labels, y_pred = pred)\n",
    "    precision = precision_score(y_true = labels, y_pred = pred)\n",
    "    f1 = f1_score(y_true = labels, y_pred = pred)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir = \"output\",\n",
    "    num_train_epochs = 1,\n",
    "    per_device_train_batch_size = 8,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/413 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 413/413 [1:07:41<00:00,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 4061.8934, 'train_samples_per_second': 0.812, 'train_steps_per_second': 0.102, 'train_loss': 0.4385557013042903, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=413, training_loss=0.4385557013042903, metrics={'train_runtime': 4061.8934, 'train_samples_per_second': 0.812, 'train_steps_per_second': 0.102, 'train_loss': 0.4385557013042903, 'epoch': 1.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 177/177 [01:52<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.trainer_utils.EvalPrediction'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3409484624862671,\n",
       " 'eval_accuracy': 0.8925035360678925,\n",
       " 'eval_precision': 0.8653001464128843,\n",
       " 'eval_recall': 0.9078341013824884,\n",
       " 'eval_f1': 0.8860569715142429,\n",
       " 'eval_runtime': 113.2985,\n",
       " 'eval_samples_per_second': 12.48,\n",
       " 'eval_steps_per_second': 1.562,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"Model_1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube_comment_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
